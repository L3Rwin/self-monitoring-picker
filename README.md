#  Self-Monitering Picker for VLN tasks
This is the repo for my work in our project in course CMU 11777 Multimodal Machine Learning. My work is based on the paper [Self-Monitoring Navigation Agent](https://arxiv.org/abs/1901.03035), where I proposed a mechanism to pick a sub-instruction segemented by ChatGPT-4o. The model is illustrated below:

<img src="https://github.com/L3Rwin/self-monitoring-picker/blob/main/model.png" width="500" height="300" alt="Model of self-monitoring picker">

Our result shown 10% increment on success rate, as illustrated below.

<img src="https://github.com/L3Rwin/self-monitoring-picker/blob/main/hyperpara_beta_v3.png.png" width="500" height="300" alt="The effect of adjusting the weight of sub-instruction">
